<div align="center">

# ğŸŒŸ Jian Zhang | å¼ èˆ°

<img src="https://readme-typing-svg.herokuapp.com?font=Space+Grotesk&size=30&duration=3000&pause=1000&color=00D9FF&center=true&vCenter=true&width=600&lines=3D+Vision+%26+AI+Researcher;Exploring+3D-Consistent+Generation;Building+Intelligent+3D+Agents" alt="Typing SVG" />

[![Homepage](https://img.shields.io/badge/ğŸŒ_Homepage-Visit_Site-00D9FF?style=for-the-badge&logo=github-pages)](https://jian-zhang-3dv.github.io/Jian-Zhang-3DV/)
[![Google Scholar](https://img.shields.io/badge/ğŸ“š_Scholar-4285F4?style=for-the-badge&logo=google-scholar&logoColor=white)](https://scholar.google.com/citations?user=qBNtBsAAAAAJ)
[![CV](https://img.shields.io/badge/ğŸ“„_CV-Download-FF6B6B?style=for-the-badge&logo=adobe-acrobat-reader)](cv/_Resume__Jian_Zhang.pdf)
[![Email](https://img.shields.io/badge/ğŸ“§_Email-Contact-FFA726?style=for-the-badge&logo=gmail&logoColor=white)](mailto:zjrandomyeah@gmail.com)

</div>

---

<table>
<tr>
<td width="30%" align="center">

<img src="jian_zhang.jpg" alt="Jian Zhang" width="180" style="border-radius: 15px;">

<br>

**ğŸ“ Graduate Student**  
*Xiamen University*

**ğŸ”¬ Research Intern**  
*Baidu Inc.*

</td>
<td width="70%">

## ğŸš€ Research Vision

> *My long-term vision follows a progressive pathway: first achieving **3D-consistent content generation**, then developing comprehensive **3D understanding**, and ultimately enabling intelligent **embodied agents** that can navigate and interact within these 3D environments.*

### ğŸ¯ Current Focus Areas

- **ğŸ¬ 3D-Consistent Content Generation**
- **ğŸ”¬ 3D Spatial Understanding** 
- **ğŸ¤– 3D Embodied Agents**
- **ğŸ® Virtual Worlds & Metaverse Applications**

</td>
</tr>
</table>

---

## ğŸ« Education & Experience

<div align="center">

<table>
<tr>
<td width="50%" align="center">

### ğŸ“ Education

**Graduate Student**  
*Xiamen University*  
ğŸ“… Sept 2023 - Present

**B.S. Artificial Intelligence**  
*Nanchang University*  
ğŸ“… Sept 2019 - June 2023

</td>
<td width="50%" align="center">

### ğŸ’¼ Experience

**Research Intern**  
*Baidu Inc.*  
ğŸ“… Aug 2025 - Present  
ğŸ¯ Video Generation Research

</td>
</tr>
</table>

</div>

---

## ğŸ“š Featured Publications

<div align="center">

### ğŸ”¥ **Recent Highlights**

</div>

### ğŸŒŸ VLM-3R: Vision-Language Models Augmented with 3D Reconstruction
**ArXiv 2025** | **Jian Zhang***, Zhiwen Fan*, et al.

Unified VLM framework incorporating 3D Reconstructive instruction tuning, processing monocular video to derive implicit 3D tokens for spatial assistance and embodied reasoning.

[![Paper](https://img.shields.io/badge/ğŸ“„_Paper-ArXiv-B31B1B?style=flat-square)](https://arxiv.org/abs/2505.20279)
[![Code](https://img.shields.io/badge/ğŸ’»_Code-GitHub-000000?style=flat-square&logo=github)](https://github.com/VITA-Group/VLM-3R)
[![Project](https://img.shields.io/badge/ğŸŒ_Project-Page-00D9FF?style=flat-square)](https://vlm-3r.github.io/)
[![Demo](https://img.shields.io/badge/ğŸ®_Demo-Interactive-FF6B6B?style=flat-square)](https://vlm-3r.github.io/)

---

### ğŸŒ DynamicVerse: Physically-Aware Multimodal Modeling for Dynamic 4D Worlds
**Preprint** | Kairun Wen*, Yuzhi Huang*, ..., **Jian Zhang**, et al.

Large-scale dataset with 100K+ videos, 800K+ masks, and 10M+ frames for understanding dynamic physical worlds with evolving 3D structure and motion.

[![Project](https://img.shields.io/badge/ğŸŒ_Project-Page-00D9FF?style=flat-square)](https://dynamic-verse.github.io/)
[![Paper](https://img.shields.io/badge/ğŸ“„_Paper-Coming_Soon-gray?style=flat-square)]()
[![Code](https://img.shields.io/badge/ğŸ’»_Code-Coming_Soon-gray?style=flat-square)]()
[![Demo](https://img.shields.io/badge/ğŸ®_Demo-Interactive-FF6B6B?style=flat-square)](https://dynamic-verse.github.io/)

---

### ğŸ† Large Spatial Model: End-to-end Unposed Images to Semantic 3D
**NeurIPS 2024** | **Jian Zhang***, Zhiwen Fan*, et al.

First real-time semantic 3D reconstruction system that directly processes unposed RGB images into semantic radiance fields in a single feed-forward pass.

[![Paper](https://img.shields.io/badge/ğŸ“„_Paper-NeurIPS-B31B1B?style=flat-square)](https://arxiv.org/abs/2410.18956)
[![Code](https://img.shields.io/badge/ğŸ’»_Code-GitHub-000000?style=flat-square&logo=github)](https://github.com/NVlabs/LSM)
[![Project](https://img.shields.io/badge/ğŸŒ_Project-Page-00D9FF?style=flat-square)](https://largespatialmodel.github.io/)

---

### âš¡ InstantSplat: Sparse-view Gaussian Splatting in Seconds
**ArXiv 2024** | Zhiwen Fan*, Kairun Wen*, ..., **Jian Zhang**, et al.

Lightning-fast sparse-view 3D scene reconstruction using self-supervised framework that optimizes 3D scene representation and camera poses simultaneously.

[![Paper](https://img.shields.io/badge/ğŸ“„_Paper-ArXiv-B31B1B?style=flat-square)](https://arxiv.org/abs/2403.20309)
[![Code](https://img.shields.io/badge/ğŸ’»_Code-GitHub-000000?style=flat-square&logo=github)](https://github.com/NVlabs/InstantSplat)
[![Project](https://img.shields.io/badge/ğŸŒ_Project-Page-00D9FF?style=flat-square)](https://instantsplat.github.io/)

---

## ğŸ¯ Research Impact & Metrics

<div align="center">

![Research Stats](https://github-readme-stats.vercel.app/api?username=Jian-Zhang-3DV&show_icons=true&theme=tokyonight&count_private=true&include_all_commits=true)

[![GitHub Streak](https://github-readme-streak-stats.herokuapp.com?user=Jian-Zhang-3DV&theme=dark&hide_border=true)](https://git.io/streak-stats)

</div>

---

## ğŸŒŸ Open for Opportunities

<div align="center">

<table>
<tr>
<td align="center" width="33%">
<h3>ğŸ¬</h3>
<b>3D-Consistent Video Generation</b>
<br><sub>Creating spatially coherent visual content</sub>
</td>
<td align="center" width="33%">
<h3>ğŸ”¬</h3>
<b>3D Spatial Understanding</b>
<br><sub>Developing comprehensive 3D perception</sub>
</td>
<td align="center" width="33%">
<h3>ğŸ¤</h3>
<b>Research Collaborations</b>
<br><sub>Building the future of 3D AI together</sub>
</td>
</tr>
</table>

### ğŸ’¼ Currently Seeking

I am actively looking for **research and engineering positions** related to:
- ğŸ¥ **3D-Consistent Video Generation**
- ğŸ¤– **Multimodal Large Models**
- ğŸŒ **3D Vision & Embodied AI**
- ğŸ® **Virtual World Technologies**

*Particularly interested in opportunities that bridge cutting-edge research with real-world applications.*

</div>

---

## ğŸ“« Let's Connect

<div align="center">

[![Email](https://img.shields.io/badge/ğŸ“§_zjrandomyeah@gmail.com-FFA726?style=for-the-badge&logo=gmail&logoColor=white)](mailto:zjrandomyeah@gmail.com)
[![Homepage](https://img.shields.io/badge/ğŸŒ_Personal_Website-00D9FF?style=for-the-badge&logo=github-pages)](https://jian-zhang-3dv.github.io/Jian-Zhang-3DV/)
[![GitHub](https://img.shields.io/badge/ğŸ’»_GitHub-000000?style=for-the-badge&logo=github)](https://github.com/Jian-Zhang-3DV)
[![Google Scholar](https://img.shields.io/badge/ğŸ“š_Google_Scholar-4285F4?style=for-the-badge&logo=google-scholar&logoColor=white)](https://scholar.google.com/citations?user=qBNtBsAAAAAJ)

---

<img src="https://capsule-render.vercel.app/api?type=waving&color=gradient&customColorList=12&height=100&section=footer&text=Thanks%20for%20visiting!&fontSize=16&fontColor=ffffff" width="100%">

*Building the future of 3D AI, one breakthrough at a time* âœ¨

</div>